# -*- coding: utf-8 -*-
import os
import random

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from PIL import Image
from torch.utils.data import DataLoader, Dataset

"""卒業研究.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19doIXLPOlswVwqUZkDulpIAnpaGoRZzf
"""

# データセットフォルダのパス
# 各自環境で変更してください
dataset_path = '/content/drive/MyDrive/hara_testdata'

dataset_path_Lineart = os.path.join(dataset_path, 'Lineart')
dataset_path_Color = os.path.join(dataset_path, 'Color')

# 画像ファイルをリストで取得
image_files_Lineart = os.listdir(dataset_path_Lineart)
image_files_Color = os.listdir(dataset_path_Color)

# テスト用の画像枚数を指定
num_test_images = 10  # 例えば10枚をテストする場合

# テスト用にランダムに画像ファイルを選択
selected_files = random.sample([file for file in image_files_Lineart if file in image_files_Color], num_test_images)


# 画像のロード関数
def load_image(image_path):
    # 画像をPILで開いてリサイズ、numpy配列に変換
    image = Image.open(image_path).resize((256, 256))  # 必要に応じてリサイズ
    image = np.array(image) / 255.0  # 0-1の範囲に正規化
    return image


# 白黒画像とカラー画像のペアをロード
def load_image_pair(filename):
    Lineart_image_path = os.path.join(dataset_path_Lineart, filename)  # 白黒画像のパス
    Color_image_path = os.path.join(dataset_path_Color, filename)  # カラー画像のパス

    Lineart_image = load_image(Lineart_image_path)  # 白黒画像をロード
    Color_image = load_image(Color_image_path)  # カラー画像をロード

    return Lineart_image, Color_image


# 選択した画像ペアをロード
image_pairs = [load_image_pair(file) for file in selected_files]


class ImageDataset(Dataset):
    def __init__(self, image_pairs):
        self.image_pairs = image_pairs

    def __len__(self):
        return len(self.image_pairs)

    def __getitem__(self, idx):
        lineart_image, color_image = self.image_pairs[idx]
        # データをテンソルに変換
        return torch.tensor(lineart_image, dtype=torch.float32).unsqueeze(0), torch.tensor(color_image, dtype=torch.float32)


dataset = ImageDataset(image_pairs)
batch_size = 16  # 任意のバッチサイズ
data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)


# Generatorの定義
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        # エンコーダー部分の層
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),  # 入力: 白黒画像
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
        )
        # デコーダー部分の層
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),  # 出力: カラー画像
            nn.Tanh()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x


# Discriminatorの定義
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),  # 入力: 白黒画像 + カラー画像
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=1),)

    def forward(self, x):
        return self.model(x)


# モデルの初期化
generator = Generator()
discriminator = Discriminator()

# オプティマイザーの設定
criterion = nn.BCELoss()  # バイナリ交差エントロピー損失
optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

# 学習ループ
num_epochs = 200  # エポック数
for epoch in range(num_epochs):
    for i, (lineart, color) in enumerate(data_loader):
        # lineartが5次元なら、次元を削除 (不要な次元の場合のみ)
        if lineart.dim() == 5:
            lineart = lineart.squeeze(1)  # [B, 1, 256, 256, 3] -> [B, 256, 256, 3]
        if lineart.dim() == 4:
          lineart = lineart.squeeze(1)

        if color.dim() == 5:
            color = color.squeeze(1)      # カラー画像も同様に処理

        if color.dim() == 4:  # [B, 256, 256, 3] の場合
            color = color.permute(0, 3, 1, 2)      # カラー画像も同じ処理

        real_images = color
        real_labels = torch.ones(real_images.size(0), 1)  # 本物ラベル
        fake_labels = torch.zeros(real_images.size(0), 1)  # 偽物ラベル

        # Generatorの学習
        optimizer_G.zero_grad()
        generated_images = generator(lineart)
        output = discriminator(torch.cat((lineart, generated_images), 1))
        g_loss = criterion(output, real_labels)  # 損失の計算
        g_loss.backward()
        optimizer_G.step()

        # Discriminatorの学習
        optimizer_D.zero_grad()
        real_output = discriminator(torch.cat((lineart, real_images), 1))
        d_loss_real = criterion(real_output, real_labels)

        fake_output = discriminator(torch.cat((lineart, generated_images.detach()), 1))
        d_loss_fake = criterion(fake_output, fake_labels)

        d_loss = d_loss_real + d_loss_fake  # 総合的な損失
        d_loss.backward()
        optimizer_D.step()

    print(f'Epoch [{epoch+1}/{num_epochs}], Loss D: {d_loss.item()}, Loss G: {g_loss.item()}')
